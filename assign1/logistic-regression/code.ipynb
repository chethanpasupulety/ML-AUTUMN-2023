{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "### Name: Pasupulety Chethan Krishna Venkat\n",
    "### Roll Number: 21CS30036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel('../../dataset/logistic-regression/Pumpkin_Seeds_Dataset.xlsx')\n",
    "\n",
    "\n",
    "# Applying logistic regression on the dataset\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_data_df, temp_data_df = train_test_split(data_df, test_size=0.5, random_state=42)\n",
    "validation_data_df, test_data_df = train_test_split(temp_data_df, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Convert DataFrame to numpy arrays\n",
    "train_data = train_data_df.to_numpy()\n",
    "validation_data = validation_data_df.to_numpy()\n",
    "test_data = test_data_df.to_numpy()\n",
    "\n",
    "# Split the data into X and y\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "X_validation = validation_data[:, :-1]\n",
    "y_validation = validation_data[:, -1]\n",
    "\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "\n",
    "\n",
    "# normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Add a column of ones to X_train, X_validation, and X_test\n",
    "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "X_validation = np.hstack((np.ones((X_validation.shape[0], 1)), X_validation))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "\n",
    "# Changing data in Y_train, Y_validation, and Y_test to 0 and 1\n",
    "# 0 for Çerçevelik and 1 for Kabakçık\n",
    "y_train = np.where(y_train == 'Çerçevelik', 0, 1)\n",
    "y_validation = np.where(y_validation == 'Çerçevelik', 0, 1)\n",
    "y_test = np.where(y_test == 'Çerçevelik', 0, 1)\n",
    "\n",
    "# Initialize theta to zeros\n",
    "theta = np.zeros(X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of data done. Moving on to the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the sigmoid function\n",
    "# returns matrix of the same shape as z with values between 0 and 1\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "# Define the gradient descent function for logistic regression\n",
    "def gradient_descent(X_train, y_train, theta, alpha, iterations):\n",
    "\n",
    "    # m= number of training examples\n",
    "    m = X_train.shape[0]\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # calculating the gradient term as an (n+1 X 1) matrix \n",
    "        # gradient matrix= (X^T)*(h(X*theta)-Y)\n",
    "\n",
    "        # h(X*theta) is a (m X 1) matrix\n",
    "        h = sigmoid(np.dot(X_train, theta))\n",
    "\n",
    "        # loss matrix= (h(X*theta)-Y) is a (m X 1) matrix\n",
    "        loss = h-y_train\n",
    "\n",
    "        # gradient matrix= (X^T)*(h(X*theta)-Y) is a (n+1 X 1) matrix\n",
    "        gradient = np.dot(X_train.T, loss)\n",
    "\n",
    "        # updating theta\n",
    "        theta = theta - (alpha / m) * gradient\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "# Predict the labels for the test set using the optimal theta\n",
    "def predict(X, theta):\n",
    "    # if the value of sigmoid function is greater than 0.5, then the label is 1\n",
    "    # if the value of sigmoid function is less than 0.5, then the label is 0\n",
    "    return np.round(sigmoid(np.dot(X,theta)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.8632478632478633\n",
      "Recall: 0.8595744680851064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setting hyperparameters\n",
    "alpha = 0.1\n",
    "iterations = 1000\n",
    "\n",
    "\n",
    "# Run gradient descent algorithm to get the optimal theta\n",
    "theta = gradient_descent(X_train, y_train, theta,alpha,iterations)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the labels for the test set using the optimal theta\n",
    "y_pred= predict(X_test, theta)\n",
    "\n",
    "\n",
    "# Defining accuracy_score function\n",
    "def accuracy_score(y_test, y_pred):\n",
    "\n",
    "    # calculating the number of true positives, true negatives, false positives, and false negatives\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "\n",
    "# Defining presicion_score function\n",
    "def presicion_score(y_test, y_pred):\n",
    "\n",
    "    # calculating the number of true positives and false positives\n",
    "\n",
    "    TP = np.sum((y_test == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_test == 0) & (y_pred == 1))\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "# Defining recall_score function\n",
    "def recall_score(y_test, y_pred):\n",
    "    # calculating the number of true positives and false negatives\n",
    "    TP = np.sum((y_test == 1) & (y_pred == 1))\n",
    "    FN = np.sum((y_test == 1) & (y_pred == 0))\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "\n",
    "# Print the accuracy, precision, and recall\n",
    "print('Logistic regression model:')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', presicion_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
